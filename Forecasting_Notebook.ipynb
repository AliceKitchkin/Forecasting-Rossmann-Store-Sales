{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliceKitchkin/Forecasting-Rossmann-Store-Sales/blob/main/Forecasting_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN5iqQON-Cqm"
      },
      "source": [
        "# Vorhersagen von Rossmann Store Sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inhaltsverzeichnis <a id=\"0\"></a> <br>\n",
        "1. [Einleitung](#1) <font color='green'>Alice</font>  \n",
        "2. [Package- und Datenimport](#2) <font color='green'>Alice</font>  \n",
        "3. [Deskriptive Analyse](#3) <font color='green'></font>  \n",
        "    3.1 [Datenüberblick](#3.1) <font color='green'>Alice</font>  \n",
        "    3.2 [Datentypen](#3.2) <font color='green'>Alice</font>  \n",
        "    3.3 [Betrachtung der Verteilung](#3.3) <font color='orange'>Alice</font>  \n",
        "    3.4 [Analyse der Kategorischen Variablen](#3.4) <font color='red'>Niklas</font>  \n",
        "    3.5 [Fehlende Werte](#3.5) <font color='green'>Alice</font>  \n",
        "    3.6 [Ausreißer](#3.6) <font color='orange'>Alice</font>  \n",
        "    3.7 [Zeitreihenanalyse](#3.7) <font color='green'>Niklas</font>  \n",
        "    3.8 [Korrelationen](#3.8) <font color='green'>Alice</font>\n",
        "4. [Daten anpassen](#4) <font color='red'>Not started</font>  \n",
        "5. [Geeignete Merkmale](#4) <font color='red'>Not started</font>  \n",
        "6. [ML Verfahren 1](#5) <font color='red'>Not started</font>  \n",
        "7. [ML Verfahren 2](#6) <font color='red'>Not started</font>  \n",
        "8. [Vergleich](#7) <font color='red'>Not started</font>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Einleitung <a id=\"1\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aFYOXeVj-kB"
      },
      "source": [
        "Dieses Jupyter Notebook dokumentiert unser Projekt für das Modul Data Mining, in dem wir die Verkaufszahlen der Rossmann-Filialen vorhersagen. Diese Aufgabe basiert auf dem Rossmann Store Sales Datensatz von [Kaggle.com](https://www.kaggle.com/competitions/rossmann-store-sales/overview), der umfangreiche Verkaufsdaten von über 1000 Filialen enthält. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBWUyUN2pCXj"
      },
      "source": [
        "## 2. Package- und Datenimport <a id=\"2\"></a> <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H5IYtG_pwKa"
      },
      "outputs": [],
      "source": [
        "import calendar\n",
        "import locale\n",
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "sns.set_style(style='white') # Hintergrund der Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "OwrlQxWBpkeB",
        "outputId": "d82e8dcb-5870-411d-9191-30c2df29e2bc"
      },
      "outputs": [],
      "source": [
        "# unzip train-file, to large for github\n",
        "# train.csv is included in .gitignore\n",
        "with zipfile.ZipFile(\"./data/train.zip\", \"r\") as zip:\n",
        "    zip.extract('train.csv', \"./data/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Maximale Anzahl an Spalten und Zeilen, beim anzeigen von Dataframes\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yq9tBkF_kT0"
      },
      "source": [
        "## 3. Deskriptive Analyse <a id=\"3\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Rossmann Store Sales-Datensatz enthält historische Verkaufsdaten für 1.115 Rossmann-Filialen. Er besteht aus drei CSV-Dateien:\n",
        "\n",
        "- train.csv: Historische Daten einschließlich Verkäufe\n",
        "- test.csv: Historische Daten ohne Verkäufe (für die Vorhersage)\n",
        "- store.csv: Zusätzliche Informationen über die Filialen\n",
        "\n",
        "Im ersten Schritt werden die Spalten der Datensätze umbenannt und in Variablen gespeichert.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spalten umbennen, damit alles einheitlich auf deutsch ist\n",
        "train_original = pd.read_csv(\"./data/train.csv\").rename(columns={\"Store\":\"Filiale\",\n",
        "                                                                 \"DayOfWeek\":\"Wochentag\",\n",
        "                                                                 \"Date\":\"Datum\",\n",
        "                                                                 \"Sales\":\"Umsatz\",\n",
        "                                                                 \"Customers\":\"Kundenanzahl\",\n",
        "                                                                 \"Open\":\"Geoeffnet\",\n",
        "                                                                 \"Promo\":\"Aktionstag\",\n",
        "                                                                 \"StateHoliday\":\"Feiertag\",\n",
        "                                                                 \"SchoolHoliday\":\"Schulferien\"})\n",
        "\n",
        "test_original = pd.read_csv(\"./data/test.csv\").rename(columns={\"Id\":\"ID\",\n",
        "                                                                  \"Store\":\"Filiale\",\n",
        "                                                                  \"DayOfWeek\":\"Wochentag\",\n",
        "                                                                  \"Date\":\"Datum\",\n",
        "                                                                  \"Open\":\"Geoeffnet\",\n",
        "                                                                  \"Promo\":\"Aktionstag\",\n",
        "                                                                  \"StateHoliday\":\"Feiertag\",\n",
        "                                                                  \"SchoolHoliday\":\"Schulferien\"})\n",
        "\n",
        "store_original = pd.read_csv(\"./data/store.csv\").rename(columns={\"Store\":\"Filiale\",\n",
        "                                                                  \"StoreType\":\"Filialentyp\",\n",
        "                                                                  \"Assortment\":\"Sortiment\",\n",
        "                                                                  \"CompetitionDistance\":\"Wettbewerberentfernung\",\n",
        "                                                                  \"CompetitionOpenSinceMonth\":\"Wettbewerber_Eroeffnet_seit_Monat\",\n",
        "                                                                  \"CompetitionOpenSinceYear\":\"Wettbewerber_Eroeffnet_seit_Jahr\",\n",
        "                                                                  \"Promo2\": \"Teilnahme_Langzeitaktion\",\n",
        "                                                                  \"Promo2SinceWeek\":\"Aktion_seit_Woche\",\n",
        "                                                                  \"Promo2SinceYear\":\"Aktion_seit_Jahr\",\n",
        "                                                                  \"PromoInterval\":\"Aktionsmonate\"})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Um in einem späteren Zeitpunkt auf die originalen Datensätze zugreifen zu können, werden diese hier separat gespeichert.\n",
        "# Außerdem werden die Datensätze _train_original_ und _store_original_ über die Spalte _Filiale_ verbunden und im neuen Datensatz \n",
        "# _train_x_store_ gespeichert. Für den Datensatz _test_original_ wird das gleiche Prozedere angewandt.\n",
        "train = train_original\n",
        "test = test_original\n",
        "store = store_original\n",
        "\n",
        "train_x_store = pd.merge(train, store)\n",
        "test_x_store = pd.merge(test, store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Datenüberblick <a id=\"3.1\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eine kurze Beschreibung der Spalten der Train-, Test- und Store-Datensätze.\n",
        "\n",
        "| Spalte                        | Umbenennung                           | Beschreibung                                                         |\n",
        "|-------------------------------|---------------------------------------|----------------------------------------------------------------------|\n",
        "| `Id`                          | `ID`                                  | Eindeutige ID für jede Filiale und jedes Datumspaar im Testdatensatz.|\n",
        "| `Store`                       | `Filiale`                             | Eindeutige ID für jede Filiale.|\n",
        "| `Sales`                       | `Wochentag`                           | Wochentag als Zahl von 1 (Montag) bis 7 (Sonntag) |\n",
        "| `Date`                        | `Datum`                               | Datum (im \"yyyy-mm-dd\" Format) |\n",
        "| `Sales`                       | `Umsatz`                              | Umsatz an einem bestimmten Tag (zu prognostizierendes Ziel).|\n",
        "| `Customers`                   | `Kundenanzahl`                        | Anzahl der Kunden an einem bestimmten Tag.|\n",
        "| `Open`                        | `Geoeffnet`                           | Indikator, ob die Filiale geöffnet war (0 = geschlossen, 1 = geöffnet).|\n",
        "| `Promo`                       | `Aktionstag`                          | Gibt an, ob ein Geschäft an diesem Tag eine Werbeaktion durchführt.|\n",
        "| `StateHoliday`                | `Feiertag`                            | Feiertagstyp (a = öffentlicher Feiertag, b = Osterfeiertag, c = Weihnachten, 0 = keiner).|\n",
        "| `SchoolHoliday`               | `Schulferien`                         | Gibt an, ob die Filiale von Schulschließungen betroffen war.|\n",
        "| `StoreType`                   | `Filialtyp`                           | Unterscheidet zwischen 4 verschiedenen Filialmodellen (a, b, c, d).|\n",
        "| `Assortment`                  | `Sortiment`                           | Beschreibt das Sortiment (a = grundlegend, b = extra, c = erweitert).|\n",
        "| `CompetitionDistance`         | `Wettbewerberentfernung`              | Entfernung in Metern zum nächsten Wettbewerbergeschäft.|\n",
        "| `CompetitionOpenSinceMonth`   | `Wettbewerber_Eroeffnet_seit_Monat`   | Gibt den Monat an, in dem der nächste Wettbewerber eröffnet wurde.|\n",
        "| `CompetitionOpenSinceYear`    | `Wettbewerber_Eroeffnet_seit_Jahr`    | Gibt das Jahr an, in dem der nächste Wettbewerber eröffnet wurde.|\n",
        "| `Promo2`                      | `Teilnahme_Langzeitaktion`            | Promo2 ist eine fortlaufende und aufeinanderfolgende Werbeaktion für einige Geschäfte (0 = nein, 1 = ja).|\n",
        "| `Promo2SinceWeek`             | `Aktion_seit_Woche`                   | Beschreibt die Kalenderwoche, in der das Geschäft an Promo2 teilnimmt.|\n",
        "| `Promo2SinceYear`             | `Aktion_seit_Jahr`                    | Beschreibt das Jahr, in der das Geschäft an Promo2 teilnimmt.|\n",
        "| `PromoInterval`               | `Aktionsmonate`                       | Beschreibt die aufeinanderfolgenden Intervalle, in denen Promo2 gestartet wird (z. B. \"Feb, Mai, Aug, Nov\").|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train-Datensatz Datenüberblick**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Test-Datensatz Datenüberblick**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(test.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Store-Datensatz Datenüberblick**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(store.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Datentypen <a id=\"3.2\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Es werden folgende neuen Spalten aus den bereits existierenden hinzugefügt:\n",
        "| Originale Spalte              | Neue Spalte                           | Beschreibung                                                              |\n",
        "|-------------------------------|---------------------------------------|---------------------------------------------------------------------------|\n",
        "| `Datum`                       | `Tag`                                 | Gibt den Tag aus der ursprünglichen Spalte Datum an (von 1 bis 31).       |\n",
        "| `Datum`                       | `Monat`                               | Gibt den Monat aus der ursprünglichen Spalte Datum an (von 1 bis 12).     |\n",
        "| `Datum`                       | `Jahr`                                | Gibt das Jahr aus der ursprünglichen Spalte Datum an.             \t    |\n",
        "| `Datum`                       | `Quartal`                             | Gibt das Quartal aus der ursprünglichen Spalte Datum an (von 1 bis 4).    |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datentypen vor Korrektur\n",
        "train_x_store.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bestehende Spalten anpassen\n",
        "train_x_store[\"Datum\"] = pd.to_datetime(train_x_store[\"Datum\"])\n",
        "train_x_store[\"Wochentag\"] = train_x_store[\"Datum\"].dt.weekday\n",
        "\n",
        "neue_spalten = {\n",
        "    \"Tag\": train_x_store[\"Datum\"].dt.day,\n",
        "    \"Monat\": train_x_store[\"Datum\"].dt.month,\n",
        "    \"Jahr\": train_x_store[\"Datum\"].dt.year,\n",
        "    \"Quartal\": train_x_store[\"Datum\"].dt.quarter\n",
        "}\n",
        "\n",
        "# Dataframe teilen, um die neuen Spalten in gewünschter Reihenfolge einzufügen\n",
        "train_x_store_before = train_x_store.iloc[:, :1]\n",
        "train_x_store_after = train_x_store.iloc[:, 1:]\n",
        "\n",
        "# Alten Dataframe mit den neuen Spalten zusammenführen\n",
        "train_x_store = pd.concat([train_x_store_before, pd.DataFrame(neue_spalten), train_x_store_after], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datentypen nach Korrektur\n",
        "display(train_x_store.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Betrachtung der Verteilung <a id=\"3.3\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Es werden die statistischen Kennzahlen für den train_x_store-Datensatz berechnet und auf drei Dezimalstellen gerundet. Zusätzlich werden nochmal die Datentypen aller Spalten angezeigt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "describe = round(train_x_store.describe(include='all'), 3)\n",
        "dtypes = pd.DataFrame(train_x_store.dtypes, columns=[\"dtypes\"]).T\n",
        "display(pd.concat([dtypes, describe]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Analyse der kategorischen Variablen <a id=\"3.4\"></a> <br>\n",
        "\n",
        "3.4.1 Filialtyp<br>\n",
        "3.4.2 Sortiment <br>\n",
        "3.4.3 Filialtyp und Sortiment <br>\n",
        "3.4.4 Feiertag <br>\n",
        "3.4.5 Geöffnet <br>\n",
        "3.4.6 Schulferien <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3.4.1 Betrachtung der Filialtypen und der Verteilung der Filialen auf diese Typen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filialentyp = pd.DataFrame(data = store[\"Filialentyp\"].value_counts()).rename(columns= {\"count\": \"Anzahl\"})\n",
        "df_filialentyp[\"Anteil\"] = round(df_filialentyp[\"Anzahl\"] / df_filialentyp[\"Anzahl\"].sum() * 100, 2).apply(lambda x: f\"{x}%\")\n",
        "df_filialentyp.sort_index(inplace = True)\n",
        "display(df_filialentyp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verteilung der Kundenzahlen und Umsätze auf die Filialtypen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filialentyp_x = train_x_store.groupby('Filialentyp')[['Kundenanzahl', 'Umsatz']].sum()\n",
        "\n",
        "df_filialentyp_x = pd.merge(df_filialentyp, df_filialentyp_x, on =\"Filialentyp\")\n",
        "\n",
        "df_filialentyp_x[\"Kundenzahl_pro_Filiale\"] = round(df_filialentyp_x[\"Kundenanzahl\"] / df_filialentyp_x[\"Anzahl\"], 0).astype(int)\n",
        "df_filialentyp_x[\"Umsatz_pro_Filiale\"] = round(df_filialentyp_x[\"Umsatz\"] / df_filialentyp_x[\"Anzahl\"], 0).astype(int)\n",
        "\n",
        "# Reihenfolge der Spalten ändern\n",
        "df_filialentyp_x = df_filialentyp_x[[\"Anzahl\", \"Anteil\", \"Kundenanzahl\", \"Kundenzahl_pro_Filiale\", \"Umsatz\", \"Umsatz_pro_Filiale\"]]\n",
        "\n",
        "display(df_filialentyp_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3.4.2 Betrachtung der Sortimente und der Verteilung der Sortimente auf die Filialen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sortimenttyp = pd.DataFrame(data = store[\"Sortiment\"].value_counts()).rename(columns= {\"count\": \"Anzahl\"})\n",
        "df_sortimenttyp[\"Anteil\"] = round(df_sortimenttyp[\"Anzahl\"] / df_sortimenttyp[\"Anzahl\"].sum() * 100, 2).apply(lambda x: f\"{x}%\")\n",
        "df_sortimenttyp.sort_index(inplace = True)\n",
        "display(df_sortimenttyp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3.4.3 Betrachtung der Sortimente und der Verteilung der Sortimente auf die Filialen unter Berücksichtigung der Filialtypen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filialentyp_x_sortimenttyp = pd.DataFrame(data = store[[\"Filialentyp\", \"Sortiment\"]].value_counts()).rename(columns= {\"count\": \"Anzahl\"})\n",
        "\n",
        "df_filialentyp_x_sortimenttyp[\"Gruppenanteil\"] = round(df_filialentyp_x_sortimenttyp[\"Anzahl\"] / df_filialentyp_x_sortimenttyp.groupby(level = \"Filialentyp\")[\"Anzahl\"].transform(\"sum\") * 100, 2).apply(lambda x: f\"{x}%\")\n",
        "df_filialentyp_x_sortimenttyp[\"Gesamtanteil\"] = round(df_filialentyp_x_sortimenttyp[\"Anzahl\"] / df_filialentyp_x_sortimenttyp[\"Anzahl\"].sum() * 100, 2).apply(lambda x: f\"{x}%\")\n",
        "df_filialentyp_x_sortimenttyp.sort_index(inplace = True)\n",
        "display(df_filialentyp_x_sortimenttyp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Von den Filialen des Typs a haben 381 das Sortiment a, damit haben 63,29% der Filialen des Typs a das Sortiment a, was 34,17% aller Filialtyps und Sortimentskombinationen ausmacht."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3.4.4 Betrachtung der Angabe Feiertag (Häufigkeit der einzelnen Ausprägungen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feiertag = pd.DataFrame(data= train_x_store[\"Feiertag\"].value_counts()).rename(columns= {\"count\": \"Anzahl\"})\n",
        "display(df_feiertag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aus irgendeinem Grund taucht die 0 (kein Feiertag) zwei mal als Ausprägungstyp auf, daher untersuchen wir den Datentyp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for index in df_feiertag.index:\n",
        "    print(f\"{index}: {type(index)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Kategorie 0 (kein Feiertag) ist einmal als str und einmal als int codiert. Das passen wir im folgenden an."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x_store[\"Feiertag\"] = train_x_store[\"Feiertag\"].astype(str)\n",
        "\n",
        "df_feiertag = pd.DataFrame(data= train_x_store[\"Feiertag\"].value_counts()).rename(columns= {\"count\": \"Anzahl\"})\n",
        "display(df_feiertag)\n",
        "\n",
        "for index in df_feiertag.index:\n",
        "    print(f\"{index}: {type(index)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feiertag[\"Anteil\"] = round(df_feiertag[\"Anzahl\"] / df_feiertag[\"Anzahl\"].sum() * 100, 2).apply(lambda x: f\"{x}%\")\n",
        "display(df_feiertag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "97% der Datenpunkte haben für das Merkmal Feiertag die Ausprägung 0 (kein Feiertag). Damit machen die Feiertage rund 3% der in den Daten enthaltenen Tage aus. Das entspricht dem Erwartungswert, da in Deutschland die Zahl der gesetzlichen Feiertage, je nach Bundesland zwischen 10 und 12 liegt (pro Jahr) --> [11 / 365 = 0,03]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3.4.5 Geöffnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geoeffnet = pd.DataFrame(data= train_x_store[\"Geoeffnet\"].value_counts()).rename(columns= {\"count\": \"Anzahl\"})\n",
        "df_geoeffnet[\"Anteil\"] = round(df_geoeffnet[\"Anzahl\"] / df_geoeffnet[\"Anzahl\"].sum() * 100, 2).apply(lambda x: f\"{x}%\")\n",
        "display(df_geoeffnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Von den Datenpunkten im Datensatz train_x_store haben 83% die Ausprägung \"Geöffnet\" = 1 und 17% die Ausprägung \"Geoeffnet\" = 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In Ferien oder an Feiertagen geöffnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geoeffnet = pd.DataFrame(data= train_x_store[[\"Schulferien\", \"Feiertag\", \"Geoeffnet\"]].value_counts()).rename(columns= {\"count\": \"Anzahl\"})\n",
        "df_geoeffnet[\"Anteil\"] = round(df_geoeffnet[\"Anzahl\"] / df_geoeffnet[\"Anzahl\"].sum() * 100, 2).apply(lambda x: f\"{x}%\")\n",
        "display(df_geoeffnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "66,88% der Datenpunkte im Datensatz train_x_store besitzen die Ausprägungskombination (Geoffnet, keine Ferien, kein Feiertag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3.4.6 Schulferien und Feiertag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ferien_x_feiertag = pd.DataFrame(data= train_x_store[[\"Schulferien\", \"Feiertag\"]].value_counts()).rename(columns= {\"count\": \"Anzahl\"})\n",
        "df_ferien_x_feiertag[\"Anteil\"] = round(df_ferien_x_feiertag[\"Anzahl\"] / df_ferien_x_feiertag[\"Anzahl\"].sum() * 100, 2).apply(lambda x: f\"{x}%\")\n",
        "display(df_ferien_x_feiertag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Fehlende Werte<a id=\"3.5\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Überblick über den zeitlichen Verlauf (liegen für jeden Tag Angaben vor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Anzahl Tage im Datensatz\n",
        "number_of_days = len(pd.unique(train_x_store[\"Datum\"]))\n",
        "\n",
        "# Anzahl an Tagen zwischen der ersten und letzten Datumsangabe\n",
        "first_day= train_x_store[\"Datum\"].min()\n",
        "last_day = train_x_store[\"Datum\"].max()\n",
        "expected_number_of_days = (last_day - first_day).days + 1\n",
        "\n",
        "print(f\"Anzahl an Tagen im Datensatz: {number_of_days}\\n\"\n",
        "      + f\"Differenz zwischen kleinster und größter Datumsangabe (in Tagen): {expected_number_of_days-1}\\n\"\n",
        "      + f\"Erwarte Anzahl an Tagen im Datensatz: {expected_number_of_days}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Anzahl der Tage für den Datenpunkte im Datensatz vorhanden sind deckt sich mit der Zeitspanne zwischen der ersten und letzten Datumsangabe im Datensatz. Es gibt also keinen Tag an dem uns alle Werte fehlen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Überischt über die Filialen:\n",
        "- liegen im Datensatz für alle Filialen und für jeden Tag Werte vor?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Anzahl an Filian\n",
        "number_of_stores = len(pd.unique(train_x_store[\"Filiale\"]))\n",
        "\n",
        "stores_with_missing_data = train_x_store[\"Filiale\"].value_counts()\n",
        "stores_with_missing_data = stores_with_missing_data[stores_with_missing_data != number_of_days]\n",
        "\n",
        "number_of_stores_with_missing_data = len(stores_with_missing_data)\n",
        "\n",
        "print(f\"Anzahl Filialen bei denen Daten fehlen: {number_of_stores_with_missing_data}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Für insgesamt 181 Filialen sind die Daten unvollständig. Der Grund dafür könnte sein, dass die Filialen im Laufe des betrachteten Zeitraus eröffnet oder geschlossen haben. Dafür betrachten wir im folgenden den zeitlichen Verlauf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x_store_gp_date = train_x_store.groupby(\"Datum\")\n",
        "\n",
        "number_of_stores_by_date = {}\n",
        "\n",
        "for date, df in train_x_store_gp_date:\n",
        "    number_of_stores_by_date[date] = len(pd.unique(df[\"Filiale\"]))\n",
        " \n",
        "df_number_of_stores_by_date = pd.DataFrame.from_dict(number_of_stores_by_date, orient = \"index\", columns= [\"Number_of_Stores\"])\n",
        "\n",
        "fig, ax = plt.subplots(figsize= (20,6))\n",
        "\n",
        "ax.set_title(\"Anzahl der Filialen für die pro Tag ein Datensatz vorliegt\")\n",
        "ax.plot(df_number_of_stores_by_date.index, df_number_of_stores_by_date[\"Number_of_Stores\"])\n",
        "ax.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Über einen Zeitraum von ca. 6 Monaten fehlen die Daten für 181 Filialen. Da der Zeitraum für den dieses Datenpunkte fehlen, innerhalb des Betrachtungshorzionts und nicht etwa am Rande liegen, ist die Theorie der Neueröffnung oder dauerhaften Schließung hinfällig."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aber wie viele Daten fehlen insgesamt?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_datapoints = len(train_x_store)\n",
        "expected_number_of_datapoint = number_of_stores * number_of_days\n",
        "\n",
        "number_of_missing_datapoints = expected_number_of_datapoint - number_of_datapoints\n",
        "\n",
        "number_of_datapoints, expected_number_of_datapoint, number_of_missing_datapoints\n",
        "print(f\"Anzahl erhaltener Datenpunkte: {number_of_datapoints}\\n\"\n",
        "      + f\"Anzahl erwarteter Datenpunkte: {expected_number_of_datapoint-1}\\n\"\n",
        "      + f\"Anzahl fehlender Datenpunkte: {number_of_missing_datapoints} ({round(number_of_missing_datapoints / expected_number_of_datapoint * 100, 2)}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insgesamt fehlen 33121 Datenpunkte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fehlende Werte in Train_x_store\n",
        "missing_data_abs = train_x_store.isnull().sum()\n",
        "missing_data_per = ( round(train_x_store.isnull().sum()/train_x_store.shape[0]*100, 2)).apply(lambda x: f\"{x}%\")\n",
        "\n",
        "missing_data_table = pd.DataFrame({\n",
        "    \"Fehlende Werte (absolut)\": missing_data_abs,\n",
        "    \"Fehlende Werte (prozentual)\": missing_data_per\n",
        "})\n",
        "\n",
        "display(missing_data_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fehlende Werte im Train-Store-Datensatz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Spalte: Wettbewerberentfernung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Im Datensatz gibt es einige Spalten mit fehlenden Werten, welche wir uns nach und nach ansehen werden. Wir beginnen mit der Spalte _Wettbewerberentfernung_, worin 2.642 NaN-Werte gefunden wurden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x_store[pd.isnull(train_x_store.Wettbewerberentfernung)].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "describe = pd.DataFrame(round(train_x_store[\"Wettbewerberentfernung\"].describe(), 3))\n",
        "display(describe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(train_x_store[\"Wettbewerberentfernung\"], bins=50, edgecolor='white')\n",
        "plt.title('Verteilung der Wettbewerberentfernungen')\n",
        "plt.xlabel('Wettbewerberentfernung')\n",
        "plt.ylabel('Anzahl')\n",
        "\n",
        "median = train_x_store[\"Wettbewerberentfernung\"].median()\n",
        "mean = train_x_store[\"Wettbewerberentfernung\"].mean()\n",
        "\n",
        "plt.axvline(median, color='red', linestyle='dashed', linewidth=1, label=f'Median: {median:.2f}')\n",
        "plt.axvline(mean, color='green', linestyle='dashed', linewidth=1, label=f'Mean: {mean:.2f}')\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir nehmen  an, dass die Daten einfach nicht vorhanden sind und ersetzen daher die fehlenden Werte in _Wettbewerberentfernung_ mit dem Median.\n",
        "Warum Median?\n",
        "-  Robustheit gegenüber Ausreißern: Der Median ist weniger anfällig für Ausreißer im Vergleich zum arithmetischen Mittelwert\n",
        "- Verteilung der Daten: Wenn die Verteilung der Daten nicht symmetrisch ist oder nicht normal verteilt ist, kann der Median oft die zentrale Tendenz der Daten besser widerspiegeln als der Mittelwert. Dies ist häufig der Fall bei Daten, die rechtsschief oder linksschief verteilt sind.\n",
        "- Der Median ist ein besserer Indikator für die zentrale Tendenz der Daten, insbesondere wenn man bedenkt, dass die Standardabweichung (7.706,913) relativ hoch ist. Dies deutet darauf hin, dass die Daten möglicherweise eine gewisse Varianz oder Ausreißer aufweisen könnten, die den Mittelwert verzerren würden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x_store[\"Wettbewerberentfernung\"].fillna(train_x_store[\"Wettbewerberentfernung\"].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Spalten: _Wettbewerber_Eroeffnet_seit_Monat_, _Wettbewerber_Eroeffnet_seit_Jahr_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(train_x_store[(train_x_store.Wettbewerberentfernung>0) & (pd.isnull(train_x_store.Wettbewerber_Eroeffnet_seit_Monat))].head())\n",
        "display(train_x_store[(train_x_store.Wettbewerberentfernung>0) & (pd.isnull(train_x_store.Wettbewerber_Eroeffnet_seit_Jahr))].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Da zwischen den Spalten Wettbewerberentfernung, _Wettbewerber_Eroeffnet_seit_Monat_ und _Wettbewerber_Eroeffnet_seit_Jahr_ kaum eine Korrelation (Korrelationskoeffizienten liegen nah um 0 herum) besteht und die Anzahl an fehlenden Werten (32%) zu groß ist um sie zu entfernen, werden die fehlenden Werte durch den jewieligen Median ersetzt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "median_W_Eroeffnet_seit_Monat = train_x_store['Wettbewerber_Eroeffnet_seit_Monat'].median()\n",
        "median_W_Eroeffnet_seit_Jahr = train_x_store['Wettbewerber_Eroeffnet_seit_Jahr'].median()\n",
        "\n",
        "train_x_store['Wettbewerber_Eroeffnet_seit_Monat'].fillna(median_W_Eroeffnet_seit_Monat, inplace=True)\n",
        "train_x_store['Wettbewerber_Eroeffnet_seit_Jahr'].fillna(median_W_Eroeffnet_seit_Jahr, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Spalten: _Teilnahme_Langzeitaktion_, _Aktion_seit_Woche_, _Aktion_seit_Jahr_, _Aktionsmonate_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Als nächstes sehen wir uns die Spalten _Teilnahme_Langzeitaktion_, _Aktion_seit_Woche_ und _Aktion_seit_Jahr_ an. Sofern eine Filiale an einer Langzeitaktion teilnimmt, sollten auch Monat und Jahr nicht fehlen. Da dies der Fall ist, können wir die fehlenden Werte durch Null ersetzen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(train_x_store[(train_x_store.Teilnahme_Langzeitaktion==1) & (pd.isnull(train_x_store.Aktion_seit_Woche))])\n",
        "display(train_x_store[(train_x_store.Teilnahme_Langzeitaktion==1) & (pd.isnull(train_x_store.Aktion_seit_Jahr))])\n",
        "display(train_x_store[(train_x_store.Teilnahme_Langzeitaktion==1) & (pd.isnull(train_x_store.Aktionsmonate))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x_store[\"Aktion_seit_Woche\"].fillna(0, inplace=True)\n",
        "train_x_store[\"Aktion_seit_Jahr\"].fillna(0, inplace=True)\n",
        "train_x_store[\"Aktionsmonate\"].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fehlende Werte im Test-Store-Datensatz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fehlende Werte in Test_x_store\n",
        "missing_data_abs = test_x_store.isnull().sum()\n",
        "missing_data_per = ( round(test_x_store.isnull().sum()/test_x_store.shape[0]*100, 2)).apply(lambda x: f\"{x}%\")\n",
        "\n",
        "missing_data_table = pd.DataFrame({\n",
        "    \"Fehlende Werte (absolut)\": missing_data_abs,\n",
        "    \"Fehlende Werte (prozentual)\": missing_data_per\n",
        "})\n",
        "\n",
        "display(missing_data_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Spalte: Geoffnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_x_store.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nur Filiale 622 hat NaNs in der Spalte Geoffnet\n",
        "display(test_x_store[pd.isnull(test_x_store.Geoeffnet)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datum extrahieren, wo Geoffnet fehlende Werte hat\n",
        "unique_dates = test_x_store[pd.isnull(test_x_store['Geoeffnet'])]['Datum'].unique()\n",
        "\n",
        "# Datensatz nach dem Datum filtern\n",
        "filtered_df = test_x_store[test_x_store['Datum'].isin(unique_dates)]\n",
        "\n",
        "# Nach Datum und Geoffnet gruppieren\n",
        "grouped = filtered_df.groupby(['Datum', 'Geoeffnet']).size().unstack(fill_value=0)\n",
        "grouped.columns = ['Anzahl_Geschlossen', 'Anzahl_Geoeffnet']\n",
        "\n",
        "display(grouped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Da die aller meisten Filialen an den ausgewählten Tagen geöffnet sind, werden die fehlenden Werte in der Spalte _Geoffnet_ ebenfalls auf 1 gesetzt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_x_store[\"Geoeffnet\"].fillna(1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Restliche Spalten mit fehlenden Werten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hier gehen wir genau so vor, wie im Train-Store-Datensatz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Median des Train-Datensatzes benutzen\n",
        "test_x_store[\"Wettbewerberentfernung\"].fillna(test_x_store[\"Wettbewerberentfernung\"].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Median des Train-Datensatzes benutzen\n",
        "median_W_Eroeffnet_seit_Monat = test_x_store['Wettbewerber_Eroeffnet_seit_Monat'].median()\n",
        "median_W_Eroeffnet_seit_Jahr = test_x_store['Wettbewerber_Eroeffnet_seit_Jahr'].median()\n",
        "\n",
        "test_x_store['Wettbewerber_Eroeffnet_seit_Monat'].fillna(median_W_Eroeffnet_seit_Monat, inplace=True)\n",
        "test_x_store['Wettbewerber_Eroeffnet_seit_Jahr'].fillna(median_W_Eroeffnet_seit_Jahr, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_x_store[\"Aktion_seit_Woche\"].fillna(0, inplace=True)\n",
        "test_x_store[\"Aktion_seit_Jahr\"].fillna(0, inplace=True)\n",
        "test_x_store[\"Aktionsmonate\"].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_x_store.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prüfen, ob noch fehlende Werte vorhanden sind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_data_abs = train_x_store.isnull().sum()\n",
        "missing_data_per = ( round(train_x_store.isnull().sum()/train_x_store.shape[0]*100, 2)).apply(lambda x: f\"{x}%\")\n",
        "\n",
        "missing_data_table = pd.DataFrame({\n",
        "    \"Fehlende Werte (absolut)\": missing_data_abs,\n",
        "    \"Fehlende Werte (prozentual)\": missing_data_per\n",
        "})\n",
        "\n",
        "display(missing_data_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_data_abs = test_x_store.isnull().sum()\n",
        "missing_data_per = ( round(test_x_store.isnull().sum()/test_x_store.shape[0]*100, 2)).apply(lambda x: f\"{x}%\")\n",
        "\n",
        "missing_data_table = pd.DataFrame({\n",
        "    \"Fehlende Werte (absolut)\": missing_data_abs,\n",
        "    \"Fehlende Werte (prozentual)\": missing_data_per\n",
        "})\n",
        "\n",
        "display(missing_data_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.6 Ausreißer <a id=\"3.6\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tage ohne Umsatz betrachten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gibt es Datensätze mit 0€ Umsatz? Wenn ja, wann und wieso ist das so?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(train_x_store[train_x_store.Umsatz==0.0])\n",
        "\n",
        "kein_umsatz_anzahl = train_x_store[train_x_store.Umsatz==0.0].shape[0]\n",
        "\n",
        "print(str(kein_umsatz_anzahl) + \" von \" + str(train_x_store.shape[0]) + \" Zeilen (\" + str(round(kein_umsatz_anzahl/train_x_store.shape[0]*100,2)) + \"%) haben keinen Umsatz.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alle Tage, an denen kein Umsatz gemacht wurde, obwohl die Filiale geöffnet war\n",
        "kein_umsatz_geoeffnet = train_x_store[(train_x_store[\"Umsatz\"]==0.0) & (train_x_store[\"Geoeffnet\"]==1)]\n",
        "display(kein_umsatz_geoeffnet.head())\n",
        "print(kein_umsatz_geoeffnet.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alle Tage, an denen Umsatz gemacht wurde, obwohl die Filiale geschlossen war\n",
        "umsatz_geschlossen = train_x_store[(train_x_store[\"Umsatz\"] != 0) & (train_x_store[\"Geoeffnet\"]==0)]\n",
        "display(umsatz_geschlossen.head())\n",
        "print(umsatz_geschlossen.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kein_umsatz_geoeffnet_grouped = kein_umsatz_geoeffnet.groupby([\"Wochentag\", \"Geoeffnet\"]).agg(\n",
        "    Anzahl_Tage=('Umsatz', 'size'),   # Anzahl der Zeilen\n",
        "    Umsatz=('Umsatz', 'sum')     # Summe der Umsätze\n",
        ")\n",
        "\n",
        "kein_umsatz_geoeffnet_grouped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.7 Zeitreihenanalyse <a id=\"3.7\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Trendanalyse: Darstellung des Umsatzes über die Zeit, um Trends, saisonale Muster oder Zyklen zu identifizieren.\n",
        "- Saisonale Muster: Analyse von Wochen-, Monats- und Jahresmustern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot der Summe des Umsatzes und der Kundenzahl im zeitlichen Verlauf\n",
        "revenue = train_x_store.groupby(\"Datum\")[\"Umsatz\"].sum()\n",
        "customer = train_x_store.groupby(\"Datum\")[\"Kundenanzahl\"].sum()\n",
        "\n",
        "fig, axs = plt.subplots(3, figsize=(30,15))\n",
        "\n",
        "\n",
        "axs[0].plot(revenue.index, revenue.values, label = \"Umsatz\")\n",
        "axs[0].set_title(\"summierter Umsatz\", fontsize=25, y=1)\n",
        "\n",
        "axs[1].plot(customer.index, customer.values, label = \"Kundenanzahl\", color = \"orange\")\n",
        "axs[1].set_title(\"summierte Kundenanzahl\", fontsize=25, y=1)\n",
        "\n",
        "axs[2].plot(revenue.index, revenue.values/revenue.mean(), label = \"Umsatz (zentriert)\")\n",
        "axs[2].plot(customer.index, customer.values/customer.mean(), label = \"Kundenanzahl (zentriert)\")\n",
        "axs[2].set_title(\"Umsatz und Kundenanzahl summiert und zentriert\", fontsize=25, y=1)\n",
        "\n",
        "for ax in axs:\n",
        "    ax.grid()\n",
        "    ax.legend()\n",
        "    \n",
        "\n",
        "fig.suptitle('Summierte Umsätze und Kundenzahlen im Verlauf der Zeit', fontsize=30, y=.95)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stores_without_missing_data = train_x_store[~train_x_store[\"Filiale\"].isin(stores_with_missing_data.index)].copy()\n",
        "\n",
        "# choose random store (id) of each store typ\n",
        "store_id_a = stores_without_missing_data[stores_without_missing_data[\"Filialentyp\"] == \"a\"][\"Filiale\"].sample(n=1).values[0]\n",
        "store_id_b = stores_without_missing_data[stores_without_missing_data[\"Filialentyp\"] == \"b\"][\"Filiale\"].sample(n=1).values[0]\n",
        "store_id_c = stores_without_missing_data[stores_without_missing_data[\"Filialentyp\"] == \"c\"][\"Filiale\"].sample(n=1).values[0]\n",
        "store_id_d = stores_without_missing_data[stores_without_missing_data[\"Filialentyp\"] == \"d\"][\"Filiale\"].sample(n=1).values[0]\n",
        "\n",
        "# store_id = 200\n",
        "\n",
        "\"\"\"\n",
        "get a sample of the training data for each choosen store id (only \"Datum\", \"Umsatz\" and \"Kundenanzahl\" is needed)\n",
        "Sample includes all data of the selected store (id)\n",
        "\"\"\"\n",
        "sample_a = train_x_store[train_x_store[\"Filiale\"]==store_id_a][[\"Datum\", \"Umsatz\", \"Kundenanzahl\"]].copy().set_index(\"Datum\", drop = True).sort_index()\n",
        "sample_b = train_x_store[train_x_store[\"Filiale\"]==store_id_b][[\"Datum\", \"Umsatz\", \"Kundenanzahl\"]].copy().set_index(\"Datum\", drop = True).sort_index()\n",
        "sample_c = train_x_store[train_x_store[\"Filiale\"]==store_id_c][[\"Datum\", \"Umsatz\", \"Kundenanzahl\"]].copy().set_index(\"Datum\", drop = True).sort_index()\n",
        "sample_d = train_x_store[train_x_store[\"Filiale\"]==store_id_d][[\"Datum\", \"Umsatz\", \"Kundenanzahl\"]].copy().set_index(\"Datum\", drop = True).sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# display(sample)\n",
        "# lags = [1, 2, 3, 4, 5, 6, 7, 14, 21, 28, 30, 60, 90]\n",
        "\n",
        "# fig, axs = plt.subplots(4, figsize= (20,12))\n",
        "# plot_acf(sample_a[\"Umsatz\"], lags = 60, zero = False, ax = axs[0])\n",
        "# plot_acf(sample_b[\"Umsatz\"], lags = 60, zero = False, ax = axs[1])\n",
        "# plot_acf(sample_c[\"Umsatz\"], lags = 60, zero = False, ax = axs[2])\n",
        "# plot_acf(sample_d[\"Umsatz\"], lags = 60, zero = False, ax = axs[3])\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# figure for subplots\n",
        "plt.figure(figsize = (24, 16))\n",
        "\n",
        "# acf and pacf for sample a (Umsatz)\n",
        "plt.subplot(421); plot_acf(sample_a[\"Umsatz\"], lags = 50, ax = plt.gca(), color = \"blue\")\n",
        "plt.subplot(422); plot_pacf(sample_a[\"Umsatz\"], lags = 50, ax = plt.gca(), color = \"blue\")\n",
        "\n",
        "# acf and pacf for sample b (Umsatz)\n",
        "plt.subplot(423); plot_acf(sample_b[\"Umsatz\"], lags = 50, ax = plt.gca(), color = \"blue\")\n",
        "plt.subplot(424); plot_pacf(sample_b[\"Umsatz\"], lags = 50, ax = plt.gca(), color = \"blue\")\n",
        "\n",
        "# acf and pacf for sample c (Umsatz)\n",
        "plt.subplot(425); plot_acf(sample_c[\"Umsatz\"], lags = 50, ax = plt.gca(), color = \"blue\")\n",
        "plt.subplot(426); plot_pacf(sample_c[\"Umsatz\"], lags = 50, ax = plt.gca(), color = \"blue\")\n",
        "\n",
        "# acf and pacf for sample d (Umsatz)\n",
        "plt.subplot(427); plot_acf(sample_d[\"Umsatz\"], lags = 50, ax = plt.gca(), color = \"blue\")\n",
        "plt.subplot(428); plot_pacf(sample_d[\"Umsatz\"], lags = 50, ax = plt.gca(), color = \"blue\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Umsatz weist eine Autokorrelation zu den Vielfachen von Sieben auf, was darauf schließen lässt, dass der Umsatz vom Wochentag abhängig ist. Die Autokorrelation gibt keinen Hinweis auf einen anderen zeitlichen Einfluss. Im Folgenden wird der zeitliche Einfluss der Woche als Saisonalität aus den Daten herausgerechnet und so der Einfluss der Saisonalität dargestellt. Aufgrund der Ergebnisse der Untersuchung der Autokorrelation wird als Periode (Dauer einer Saisonalität) 7 gewählt. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stl_weekly_umsatz = seasonal_decompose(sample_a[\"Umsatz\"], model = \"additive\", period = 7)\n",
        "stl_yearly_umsatz = seasonal_decompose(sample_a[\"Umsatz\"], model = \"additive\", period = 365)\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (20, 10)})\n",
        "stl_weekly_umsatz.plot().suptitle('Wöchentliche Saisonalität Filialtyp A', fontsize=30, y=1.05)\n",
        "stl_yearly_umsatz.plot().suptitle('Jährliche Saisonalität Filialtyp A', fontsize=30, y=1.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bei der Zerlegung des Umsatzes in einen Wiederkehrenden Term (Saisonalität - Seasonal), einen den zugrunden liegenden Trend und einen unerklärlichen Teil (Residuen - Resid) ergeben sich, bei einer Periodenlänge von 7 bzw. 365 Tagen die oberen Plots. Auch wenn die Autokorrelation keinen Hinweis auf weitere zeitliche Einflüsse als die Woche (den Wochentag) gegeben hat, weist der Trend markante und wiederkehrende Erhebungen auf, die auf eine weitere Saisonalität hindeuten. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stl_weekly_umsatz = seasonal_decompose(sample_b[\"Umsatz\"], model = \"additive\", period = 7)\n",
        "stl_yearly_umsatz = seasonal_decompose(sample_b[\"Umsatz\"], model = \"additive\", period = 365)\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (20, 10)})\n",
        "stl_weekly_umsatz.plot().suptitle('Wöchentliche Saisonalität Filialtyp B', fontsize=30, y=1.05)\n",
        "stl_yearly_umsatz.plot().suptitle('Jährliche Saisonalität Filialtyp B', fontsize=30, y=1.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stl_weekly_umsatz = seasonal_decompose(sample_c[\"Umsatz\"], model = \"additive\", period = 7)\n",
        "stl_yearly_umsatz = seasonal_decompose(sample_c[\"Umsatz\"], model = \"additive\", period = 365)\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (20, 10)})\n",
        "stl_weekly_umsatz.plot().suptitle('Wöchentliche Saisonalität Filialtyp C', fontsize=30, y=1.05)\n",
        "stl_yearly_umsatz.plot().suptitle('Jährliche Saisonalität Filialtyp C', fontsize=30, y=1.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stl_weekly_umsatz = seasonal_decompose(sample_d[\"Umsatz\"], model = \"additive\", period = 7)\n",
        "stl_yearly_umsatz = seasonal_decompose(sample_d[\"Umsatz\"], model = \"additive\", period = 365)\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (20, 10)})\n",
        "stl_weekly_umsatz.plot().suptitle('Wöchentliche Saisonalität  Filialtyp D', fontsize=30, y=1.05)\n",
        "stl_yearly_umsatz.plot().suptitle('Jährliche Saisonalität Filialtyp D', fontsize=30, y=1.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fig, axs = plt.subplots(3, figsize= (20,12))\n",
        "# plot_acf(sample[\"Kundenanzahl\"], lags = len(sample)-1, zero = False, ax = axs[0])\n",
        "# plot_acf(sample[\"Kundenanzahl\"], lags = 60, zero = False, ax = axs[1])\n",
        "# plot_pacf(sample[\"Kundenanzahl\"], lags = 60, zero = False, ax = axs[2])\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Kundenanzahl weist eine Autokorrelation zu den Vielfachen von Sieben auf, was darauf schließen lässt, dass die Kundenanzahl vom Wochentag abhängig ist. Die Autokorrelation gibt keinen Hinweis auf einen anderen zeitlichen Einfluss. Im Folgenden wird der zeitliche Einfluss der Woche als Saisonalität aus den Daten herausgerechnet und so der Einfluss der Saisonalität dargestellt. Aufgrund der Ergebnisse der Untersuchung der Autokorrelation wird als Periode (Dauer einer Saisonalität) 7 gewählt. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stl_weekly_kundenzahl = seasonal_decompose(sample_a[\"Kundenanzahl\"], model = \"additive\", period=7)\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (20, 10)})\n",
        "stl_weekly_kundenzahl.plot().suptitle('Wöchentliche Saisonalität Filialtyp A', fontsize=30, y=1.05)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bei der Zerlegung der Kundenanzahl in einen Wiederkehrenden Term (Saisonalität - Seasonal), einen den zugrunden liegenden Trend und einen unerklärlichen Teil (Residuen - Resid) ergeben sich, bei einer Periodenlänge von 7 bzw. 365 Tagen die oberen Plots. Auch wenn die Autokorrelation keinen Hinweis auf weitere zeitliche Einflüsse als die Woche (den Wochentag) gegeben hat, besitzt der Trend markante und wiederkehrende Erhebungen, die auf eine weitere Saisonalität hindeuten. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stl_weekly_kundenzahl = seasonal_decompose(sample_b[\"Kundenanzahl\"], model = \"additive\", period=7)\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (20, 10)})\n",
        "stl_weekly_kundenzahl.plot().suptitle('Wöchentliche Saisonalität Filialtyp B', fontsize=30, y=1.05)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stl_weekly_kundenzahl = seasonal_decompose(sample_c[\"Kundenanzahl\"], model = \"additive\", period=7)\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (20, 10)})\n",
        "stl_weekly_kundenzahl.plot().suptitle('Wöchentliche Saisonalität Filialtyp C', fontsize=30, y=1.05)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stl_weekly_kundenzahl = seasonal_decompose(sample_d[\"Kundenanzahl\"], model = \"additive\", period=7)\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (20, 10)})\n",
        "stl_weekly_kundenzahl.plot().suptitle('Wöchentliche Saisonalität Filialtyp D', fontsize=30, y=1.05)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eine Filiale zufällig wählen\n",
        "store_id = store[\"Filiale\"].sample(n=1).values[0]\n",
        "\n",
        "# Den Datensatz auf die zuvor festgelegte Filiale filtern\n",
        "sample = train_x_store[train_x_store[\"Filiale\"]==store_id].copy()\n",
        "sample_gp_weekday = sample.groupby(by=[\"Wochentag\"])\n",
        "\n",
        "weekdays = []\n",
        "mean_revenue = []\n",
        "mean_numb_of_customers = []\n",
        "for weekday, df in sample_gp_weekday:\n",
        "    weekdays.append(weekday[0])\n",
        "    mean_revenue.append(df[\"Umsatz\"].mean())\n",
        "    mean_numb_of_customers.append(df[\"Kundenanzahl\"].mean())\n",
        "    \n",
        "\n",
        "df_avg_week = pd.DataFrame(data = {\"Wochentag\": weekdays, \"Umsatz\": mean_revenue, \"Kundenanzahl\": mean_numb_of_customers})\n",
        "display(df_avg_week)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "locale.setlocale(locale.LC_ALL, 'de_DE')\n",
        "\n",
        "fig, axs = plt.subplots(2, figsize = (10,10))\n",
        "\n",
        "axs[0].bar(calendar.day_name, df_avg_week.Umsatz, label = \"durchchnittlicher Umsatz\")\n",
        "axs[1].bar(calendar.day_name, df_avg_week.Kundenanzahl, label = \"durchschnittliche Kundenanzahl\")\n",
        "\n",
        "for ax in axs:\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05))\n",
        "    ax.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_gp_day = sample.groupby(by=[\"Tag\"])\n",
        "\n",
        "days = []\n",
        "mean_revenue = []\n",
        "mean_numb_of_customers = []\n",
        "for day, df in sample_gp_day:\n",
        "    days.append(day[0])\n",
        "    mean_revenue.append(df[\"Umsatz\"].mean())\n",
        "    mean_numb_of_customers.append(df[\"Kundenanzahl\"].mean())\n",
        "    \n",
        "\n",
        "df_avg_day_of_month = pd.DataFrame(data = {\"Tag\": days, \"Umsatz\": mean_revenue, \"Kundenanzahl\": mean_numb_of_customers})\n",
        "display(df_avg_day_of_month.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, figsize = (20,10))\n",
        "\n",
        "axs[0].bar(df_avg_day_of_month.Tag, df_avg_day_of_month.Umsatz, label = \"durchchnittlicher Umsatz\")\n",
        "axs[1].bar(df_avg_day_of_month.Tag, df_avg_day_of_month.Kundenanzahl, label = \"durchschnittliche Kundenanzahl\")\n",
        "\n",
        "for ax in axs:\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05))\n",
        "    ax.grid()\n",
        "\n",
        "fig.suptitle('Durchschnittliche Verteilung des Umsatzes und der Kundenzahl über einen Monat', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.8 Korrelationsanalyse <a id=\"3.8\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Korrelationsmatrix auf den gesamten Train-Store-Datensatz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Korrelationsmatrix beinhaltet alle numerischen Spalten aus dem _train_x_store_ Datensatz. Dabei wird bei der Pearson-Korrelation mit binären Variablen genauso wie mit kontinuierlichen Variablen umgegangen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spalten mit numerischen Werten (Strings und kategorische Werte ausgeschlossen)\n",
        "train_x_store_only_nr = train_x_store.select_dtypes(include=['number'])\n",
        "\n",
        "# Korrelationsmatrix nach Pearson-Verfahren erstellen\n",
        "corr_matrix_all = train_x_store_only_nr.corr(\"pearson\")\n",
        "display(corr_matrix_all.head())\n",
        "\n",
        "# Nur unteres Dreieck in der Korrelationsmatrix ziehen\n",
        "my_mask = np.triu(np.ones_like(corr_matrix_all, dtype=bool))\n",
        "\n",
        "# Korrelationsmatrix erstellen und formatieren\n",
        "plt.figure(figsize=(12,6))\n",
        "plot = sns.heatmap(corr_matrix_all, cmap=\"RdBu\", vmin=-1, vmax=1, annot=True, fmt=\"0.3f\", mask=my_mask)\n",
        "plot.set_title(\"Korrelationsmatrix gesamter Train-Store-Datensatz\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Korrelationsmatrix einer zufälligen Filiale des Train-Store-Datensatzes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eine Filiale zufällig wählen\n",
        "store_id = store[\"Filiale\"].sample(n=1).values[0]\n",
        "\n",
        "# Den Datensatz auf die zuvor festgelegte Filiale filtern\n",
        "sample = train_x_store[train_x_store[\"Filiale\"]==store_id].copy()\n",
        "\n",
        "# Spalten mit numerischen Werten (Strings und kategorische Werte ausgeschlossen)\n",
        "sample_only_nr = sample.select_dtypes(include=['number'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Korrelationsmatrix nach Pearson-Verfahren erstellen\n",
        "corr_matrix_sample = sample_only_nr.corr(\"pearson\")\n",
        "\n",
        "# Nur unteres Dreieck in der Korrelationsmatrix ziehen\n",
        "my_mask = np.triu(np.ones_like(corr_matrix_sample, dtype=bool))\n",
        "\n",
        "# Korrelationsmatrix erstellen und formatieren\n",
        "plt.figure(figsize=(12,6))\n",
        "plot = sns.heatmap(corr_matrix_sample, cmap=\"RdBu\", vmin=-1, vmax=1, annot=True, fmt=\"0.3f\", mask=my_mask)\n",
        "plot.set_title(f\"Korrelationsmatrix der Filiale {store_id}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Korrelationsmatrix weist einen großen weißen Bereich mit NaN-Werten auf, da diese Spalten konstante Werte enthalten. In solchen Fällen ist die Standardabweichung gleich null, was zur Folge hat, dass die Berechnung der Korrelation nicht möglich ist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Korrelationsmatritzen miteinander vergleichen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Positive Werte zeigen an, dass der Korrelationskoeffizient in der ersten Matrix größer ist als in der zweiten Matrix.\n",
        "- Negative Werte zeigen an, dass der Korrelationskoeffizient in der zweiten Matrix größer ist als in der ersten Matrix.\n",
        "- Ein Wert von Null in der Differenzmatrix bedeutet, dass sich die Korrelationskoeffizienten zwischen den beiden Matrizen nicht unterscheiden, d.h., die Korrelationen sind für diese Variablenpaare gleich."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Differenz der beiden Korrelationsmatritzen nach Pearson-Verfahren erstellen\n",
        "diff_matrix = corr_matrix_all - corr_matrix_sample\n",
        "\n",
        "# Nur unteres Dreieck in der Korrelationsmatrix ziehen\n",
        "my_mask = np.triu(np.ones_like(diff_matrix, dtype=bool))\n",
        "\n",
        "# Korrelationsmatrix erstellen und formatieren\n",
        "plt.figure(figsize=(12,6))\n",
        "plot = sns.heatmap(diff_matrix, cmap=\"RdBu\", vmin=-1, vmax=1, annot=True, fmt=\"0.3f\", mask=my_mask)\n",
        "plot.set_title(\"Differenzmatrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqGWloyK_pKW"
      },
      "source": [
        "## Geeignete Merkmale <a id=\"4\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definieren Sie geeignete Merkmale (Features) für die Klassifikation/Regression/Clustering. Versuchen Sie dabei, aus den bestehenden Merkmale neue abzuleiten und überlegen Sie sich zusätzliche z.B. mit externen Informationen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Umsatz je Kunde\n",
        "example = train_x_store_after.copy()\n",
        "example[\"UmsatzProKunde\"] = example[\"Umsatz\"] / example[\"Kundenanzahl\"]\n",
        "\n",
        "display(example[\"UmsatzProKunde\"])\n",
        "\n",
        "# 2. Klassenbildung über Wettbewerberentfernung\n",
        "## Bspw. [0, <250, <500 ...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJTuYUGp_17r"
      },
      "source": [
        "## Machine Learning Verfahren 1 <a id=\"5\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIOrDbWz_9vt"
      },
      "source": [
        "## Machine Learning Verfahren 2 <a id=\"6\"></a> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHn8zP2f__P0"
      },
      "source": [
        "## Vergleich der Machine Learning Verfahren <a id=\"7\"></a> <br>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMYuAFrHlEVIBdFp5vtNX+s",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
